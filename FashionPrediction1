
# coding: utf-8

# ## Import all packages

# In[30]:


import os
import sys

import scipy.io
import scipy.misc
from scipy.misc import toimage
from scipy.io import loadmat
from scipy import ndimage


import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

from PIL import Image
from nst_utils import *
import numpy as np
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf

#%matplotlib inline

from keras import layers
from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D
from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D
from keras.models import Model
from keras.preprocessing import image
from keras.utils import layer_utils
from keras.utils.data_utils import get_file
from keras.utils.vis_utils import model_to_dot
from keras.utils import plot_model
import keras.backend as K
from keras.applications.imagenet_utils import preprocess_input
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

#from kt_utils import *
#import pydot

K.set_image_data_format('channels_last')

from IPython.display import display
from IPython.display import Image as _Imgdis
from IPython.display import SVG

from time import time
from time import sleep

from sklearn.model_selection import train_test_split


# ## Data Augmentation

# In[140]:


folder = "ClothingAttributeDataset/images/"
onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))] # read all files in the 'folder'
onlyfiles = onlyfiles

#file names in the folder
train_files = []

for _file in onlyfiles:
    train_files.append(_file)
    
print("Files in train_files: %d" % len(train_files))



datagen = ImageDataGenerator(
        rotation_range=45,
        width_shift_range=0.3,
        height_shift_range=0.3,
        shear_range=0.3,
        zoom_range=0.3,
        horizontal_flip=True,
        fill_mode='nearest')

for _file in train_files:
    img = load_img(folder + "/" + _file)  # this is a PIL image
    img = img.resize((image_height, image_width))
    # Convert to Numpy Array
    x = img_to_array(img)  
    x = x.reshape((1,) + x.shape)
    
    num_image_generated = 0
    for batch in datagen.flow(x, batch_size=1, save_to_dir='preview', save_prefix=_file+'_', save_format='jpeg'):
        num_image_generated += 1
        if num_image_generated > 20:
            break # stop the loop after num_image_generated iterations
        
    #x = x.reshape((image_height, image_width, channels))
    #toimage(data).show()
    # Normalize
    x = (x - 128.0) / 128.0


# ## Read X from augmented data dir

# In[52]:


folder = "preview/"
onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))] # read all files in the 'folder'

#file names in the folder
train_files = []

for _file in onlyfiles:
    if _file == '.DS_Store':
        continue
    train_files.append(_file)

dataset = np.ndarray(shape=(len(train_files), image_height, image_width, channels),
                     dtype=np.float32)

# Original Dimensions
#image_width = 267
#image_height = 400
#ratio = 4

image_width = 224
image_height = 224
channels = 3

i=0
for _file in train_files:
    img = load_img(folder + "/" + _file)  # this is a PIL image
    img = img.resize((image_height, image_width))
    x = img_to_array(img)  
    dataset[i] = x
    i += 1
    if i % 250 == 0:
        print("%d images to array" % i)
print("All images to array!")


# In[54]:


dataset.shape


# ## Read y 

# In[136]:


folder = "ClothingAttributeDataset/labels/"
onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]
y_train = []
label_ls = []
#np.zeros((1856*dataset.shape[0],1))#


# In[137]:


###GET RIDE OF onlyfiles[1:2] later!!###
for _file in onlyfiles:
    if _file == '.DS_Store':
        continue
    x = loadmat('ClothingAttributeDataset/labels/' + _file)
    x = x['GT'].repeat(dataset.shape[0])
    y_train.append(x)
    file_name = _file[0:_file.find('.mat')]
    label_ls.append(file_name)

y_train = np.asarray(y_train)
print(label_ls)


# ## Train test data split

# In[21]:


X = dataset
y = y_train
y[np.isnan(y)] = -1
print('y_label nan replaced with -1')
np.where(np.asanyarray(np.isnan(y_train)))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)

X_train.shape
X_test.shape


# ## Loading pre-trained weights

# In[23]:


from keras import applications

vgg_model = applications.VGG16(weights='imagenet',
                               include_top=False,
                               input_shape=(224, 224, 3))

# Creating dictionary that maps layer names to the layers
layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])

# Getting output tensor of the last VGG layer that we want to include
x = layer_dict['block2_pool'].output

# Stacking a new simple convolutional network on top of it    
x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(2, activation='softmax')(x)

# Creating new model. Please note that this is NOT a Sequential() model.
from keras.models import Model
custom_model = Model(input=vgg_model.input, output=x)

# Make sure that the pre-trained bottom layers are not trainable
for layer in custom_model.layers[:7]:
    layer.trainable = False

# Do not forget to compile it
custom_model.compile(loss='categorical_crossentropy',
                     optimizer='rmsprop',
                     metrics=['accuracy'])


# ## Create a new network with bottom layers taken from VGG

# In[24]:


custom_model.fit(x=X_train, y=y_train, batch_size=16, epochs=1)


# In[ ]:


### START CODE HERE ### (1 line)
preds = custom_model.evaluate(x = X_test,y = y_test)
### END CODE HERE ###
print()
print ("Loss = " + str(preds[0]))
print ("Test Accuracy = " + str(preds[1]))

